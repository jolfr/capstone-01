{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6coRtYMknP8g"
   },
   "source": [
    "This is the third step in the Data Science Method. We introduced this topic in the last subunit. With Data Wrangling out of the way we can progress to the Exploratory Data Analysis section. In this exercise, you will learn to build data profiles and plots, including relationship plot and data correlation plot. You will also implement k-means clustering, complete clusters, and update data frame as a CSV file. Let's get started! \n",
    "  \n",
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  * Data Collection \n",
    "   * Data Organization\n",
    "  * Data Definition \n",
    "  * Data Cleaning\n",
    " \n",
    "3.   **Exploratory Data Analysis** \n",
    " * Build data profile tables and plots\n",
    "        - Outliers & Anomalies\n",
    " * Explore data relationships\n",
    " * Identification and creation of features\n",
    "\n",
    "4.   Pre-processing and Training Data Development\n",
    "  * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   Modeling \n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGpKRX884-Vz"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages as we did in step 2 and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ND33_51f4-V0"
   },
   "outputs": [],
   "source": [
    "#load python packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RaogaD74-V6"
   },
   "source": [
    "**<font color='teal'> If you need to change your path refer back to step 2 on how to do that. Then load the csv file you created in step 2, remember it should be saved inside your data subfolder and print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJOG5gwW4-V7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZDJfp-RlDZX"
   },
   "source": [
    "# Build data profile tables and plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "**<font color='teal'> Print out the summary stats table transposed to fit on the screen using the `describe()` function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5sEVbbjZyGC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qbsc0sfW4-WI"
   },
   "source": [
    "**<font color='teal'> Histograms are an excellent way to review the range and density of values for each numeric features in your data set and build data profiles. Plot the histograms for all numeric features and adjust the bins size to 25.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PX_gPWmAZyHW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IEI0Kzj4-WN"
   },
   "source": [
    "Look for similarities in the features that may indicate that they are duplicates or highly correlated features. Make a note of your findings and any other interesting insights you find about these numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cL107nfB4-WO"
   },
   "source": [
    "**<font color='teal'> Okay, now you should be getting a sense for what the data look like. Let's create a barplot for the categorical features `Region` and `state` where the heights of the bars are the counts of each level in that variable. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYHlF-jM4-WP"
   },
   "source": [
    "**<font color='teal'>State Levels Plot</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET_UkmR-4-WQ"
   },
   "outputs": [],
   "source": [
    "# Uncomment the following code to get your visualization started \n",
    "# f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# In the following brackets, we want the value_counts() of the states \n",
    "x = pd.DataFrame(df.state._ _ _)\n",
    "\n",
    "# Get the state names by calling list() on the x.index\n",
    "names = _ _ _(x.index)\n",
    "\n",
    "# Get the values by plugging x.state into the list() function\n",
    "values = list(_ _ _)\n",
    "\n",
    "# We're now going to call the barplot() method on our sns seaborn object. \n",
    "# If you don't have a searborn object yet, make sure you've imported seaborn as sns in your imports above. \n",
    "sns._ _ _(x=values, y=names, palette=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2Qx9U_94-WV"
   },
   "source": [
    "**<font color='teal'>Region Levels Plot</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHZoLfzf4-WW"
   },
   "outputs": [],
   "source": [
    "# Now do the same for regions! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FuztX1lb4-Wa"
   },
   "source": [
    "By reviewing the State and Regions counts plots you should notice that the Region feature is nearly identical to the state and therfore we can remove from the dataframe.**<font color='teal'> Remove the `Region` column using the drop function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRsTmTSX4-Wc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Anamolies & Outliers - Review boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVbFWUNb4-Wf"
   },
   "source": [
    "**<font color='teal'> Print boxplot for every column</font>**\n",
    "\n",
    "Hint: you'll see the methodology here in this article on Exploratory Data Analysis [here](nce-method-dsm-exploratory-data-analysis-bc84d4d8d3f9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW3D-WlDZyGG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blzjJLn54-Wl"
   },
   "source": [
    "You need to create boxplots and  histograms to evaluate the data for potential outliers or data anomalies. Generally, outliers are defined as observations that differ significantly from the other values in the dataset or feature. \n",
    "\n",
    "Reviewing the distribution of values by column will help you  interpret this. Outliers are extreme values that fall far outside the mean and standard deviation of a set of observations. They  can mislead the training process in building machine learning models. Outliers may be real anomalies in the observations or artificial errors. \n",
    "\n",
    "One method for outlier analysis is extreme value analysis using a boxplot, which assumes a normal distribution. The figure below describes the components of a boxplot. Notice the outlier is the point outside the upper whisker end. \n",
    "\n",
    "![](AnnotatedBoxplot.png)  \n",
    "<font color='teal'>Follow these steps:  \n",
    "\n",
    "1. Create boxplots - earlier step\n",
    "2. Apply outlier removal using the Interquartile range or replacement \n",
    "3. Review how many observations were removed</font>\n",
    "\n",
    "Hint: Recall from your statistics prework that a common definition of an outlier is an observation lying more than (1.5 * the Interquartile range) above the third quartile, or more than just that much below the first quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILrNrad44-Wm"
   },
   "outputs": [],
   "source": [
    "# Let's get the Interquartile range, or IQR. This is equal to Q3 - Q1. \n",
    "# First, let's use the quantile() method to get the first quartile, and store it in a variable called Q1.\n",
    "# We'll want to plug 0.25 into the quantile method. \n",
    "Q1 = df.quantile(_ _ _)\n",
    "\n",
    "# Now get Q3 and store in a variable called Q3. \n",
    "\n",
    "# Now calculate the IQR, storing it in a variable called IQR.\n",
    "\n",
    "# Make a variable called `dfno`, and assign it the value: df[~((df < (Q1 - 1.5 * IQR)) |(df> (Q3 + 1.5 * IQR))).any(axis=1)]. \n",
    "# This filters on our existing dataframe, picking out just those observations that are NOT outliers. \n",
    "\n",
    "# We now want to make a boxplot of this new dataframe dfno. \n",
    "_ _ _ = _ _ _._ _ _(grid=False, vert=False,fontsize=15, figsize=(12,15))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW-fSw0l4-Ws"
   },
   "outputs": [],
   "source": [
    "# Print the shapes of our dataframes df and dfno to compare the number of observations in each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to discover and remove outliers, and what counts as a sensible way of doing so depends on your problem, your methodology for solving that problem, and the nature of your data. \n",
    "\n",
    "Each method will have its merits and demerits. As we can see, in this instance, we've lost a great many observations! \n",
    "\n",
    "There is no hard and fast rule as to which outlier removal method is best in all cases, and you will have to exercise your good judgement in arriving at an appropriate method for your problem at hand. We will cover outlier removal in more depth in units 7 (Data Wrangling) and 10 (Statistics for Exploratory Data Analysis) of the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ovv76_nQlUh1"
   },
   "source": [
    "There are many possible response variables you could have identified in Step 1 of this guided capstone. However, for the rest of this guided capstone project, we will focus on increasing revenue by increasing the lift ticket prices and the number of days the resort is open per year. In this case, we need to investigate the expected lift ticket price for Big Mountain based on all the other given resort characteristics. In addition, we want to predict the number of days the resort will be open each season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jbwlAAk4-Wx"
   },
   "source": [
    "<font color='teal'>**Review the `AdultWeekday`,`AdultWeekend` response variable distributions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "og2uVb9rlUGB"
   },
   "outputs": [],
   "source": [
    "# Make a histogram of the 'AdultWeekday' column of the dfno dataframe. \n",
    "# You'll want to call hist() on that column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYqUmw2j4-W1"
   },
   "outputs": [],
   "source": [
    "# Do the same but with the AdultWeekend column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJdu2biU4-W4"
   },
   "source": [
    "<font color='teal'>**Review the `daysOpenLastYear`,`projecteDaysOpen` response variable distributions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_za8i8O4-W5"
   },
   "outputs": [],
   "source": [
    "# Do the same as above! You got this :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kA5coRq4-W9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajO60aWZ4-XA"
   },
   "source": [
    "After reviewing these respons varible distributions, there doesn't appear to be any data issues to mitigate. Now, we move on to investigating feature relationship and interactions between the features the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5harOR1X-cZ"
   },
   "source": [
    "# Explore data relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1zsIb5h4-XC"
   },
   "source": [
    "<font color='teal'>**Create pairplots or what is commonly referred to as biplots**</font>\n",
    "\n",
    "Hint: pairplots are covered in this article on EDA [here](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-exploratory-data-analysis-bc84d4d8d3f9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EY1Cnmrf4-XD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idsd9zX44-XG"
   },
   "source": [
    "# Identification and creation of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOi-cwQx4-XH"
   },
   "source": [
    "<font color='teal'>**Create a Pearson correlation heatmap**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehAKkcQz4-XI"
   },
   "outputs": [],
   "source": [
    "#Calculate the correlation coefficients\n",
    "corr =\n",
    "#plot it in the next line\n",
    "corr.round(2).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_cyPDSe4-XL"
   },
   "source": [
    "When reviewing the Pearson correlation coefficient heatmap, you can see substantial differences in the correlations compared to the response variable(s) as well as in the features when compared to each other. The heatmap helps identify features that suffer from multi-collinearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcO2qobH4-XM"
   },
   "source": [
    "<font color='teal'>**Use the correlation matrix displayed in the heatmap to select and remove collinear features. Remember to exclude the response variable(s) from the matrix to ensure they are retained in your final model development dataset. Then select those features that are more than 95% correlated for removal.**</font>\n",
    "\n",
    "Step 1: Create a correlation matrix that excludes your response variables. \n",
    "\n",
    "Step 2: Select the upper triangle of the correlation matrix. This is because a correlation matrix actually contains the same information, twice over!\n",
    "\n",
    "Step 3: Find the index of feature columns with a correlation greater than 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7MwPeW_4-XN"
   },
   "outputs": [],
   "source": [
    "# Step 1. Call the variable corr_matrix\n",
    " _ _ _ = dfno._ _ _(['_ _ _','AdultWeekend','_ _ _','projectedDaysOpen'], axis=1).corr().abs()\n",
    "\n",
    "# Step 2. Uncomment the following code to get the upper triangle of the correlation matrix \n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Step 3. This code iterates through our columns and gets the index of any that have a correlation > 0.95\n",
    "# Call the variable to_drop, get the columns of our 'upper' variable, make sure the threshold is 0.95.\n",
    "_ _ _ = [column for column in _ _ _.columns if any(upper[column] > _ _ _)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMjMQkC7QGyb"
   },
   "outputs": [],
   "source": [
    "# Let's see those features! \n",
    "print('Features selected to drop include:',to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpGCEljBQGyd"
   },
   "outputs": [],
   "source": [
    "print('Reduced dataframe size: ',dfno.drop(dfno[to_drop], axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace dfno by the result of dropping the columns in the to_drop variable from it\n",
    "_ _ _ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80_xI8GT4-XQ"
   },
   "source": [
    "Now we address the feature creation piece of this step. We can create additional features through many methods such as: combining several features, grouping features into bins, or even by applying an unsupervised classification algorithm, such as k-means clustering and using the clusters as features in our model development dataset.\n",
    "\n",
    "Clustering essentially finds patterns in data when we don't know in advance what we're looking for. The K-means algorithm is one way of doing clustering. It puts our data into groups (or 'clusters') which can then become features for further analysis. What the k-means algorithm outputs, though, depends on the number of clusters we set out to have. We will use a method called 'Elbow plotting' to determine this number. \n",
    "\n",
    "We will cover clustering and k-means thoroughly in the Unsupervised Learning unit of this course, but for now, we'll use it for feature creation alone, which is an integral part of Exploratory Data Analysis. Don't worry if you don't understand the details just yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmuto_od4-XR"
   },
   "source": [
    "Run the next two cells below to create an Elbow plot. The Elbow plot is a diagnostic tool that helps us determine the number of clusters to include in our k-means clustering implementation. \n",
    "\n",
    "In this example, the error between clusters and within clusters is compared for a range of 1 to 11 clusters, and it appears the elbow is between two and four, therefore we set the parameter k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i43iaNs24-XS"
   },
   "outputs": [],
   "source": [
    "#from sklearn.cluster import KMeans\n",
    "#x = dfno.drop(['Name','state'], axis =1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLNoqXQN4-XV"
   },
   "outputs": [],
   "source": [
    "#Error =[]\n",
    "#for i in range(1, 11):\n",
    "#   kmeans = KMeans(n_clusters = i).fit(x)\n",
    "#    kmeans.fit(x)\n",
    "#    Error.append(kmeans.inertia_)\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(range(1, 11), Error)\n",
    "#plt.title('Elbow method')\n",
    "#plt.xlabel('No of clusters')\n",
    "#plt.ylabel('Error')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8BrP0e_4-XY"
   },
   "source": [
    "<font color='teal'>**Fit the kmeans algorithm with the k parameter set to three and plot the results.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TfakkUd4-XY"
   },
   "outputs": [],
   "source": [
    "# This code will fit the k-means algorithm with our k parameter set to three, and plot the results. Cool, huh? \n",
    "kmeans3 = KMeans(n_clusters=3)\n",
    "y_kmeans3 = kmeans3.fit_predict(x)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_kmeans3, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans3.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hvmu-OX24-Xb"
   },
   "source": [
    "<font color='teal'>**Add the clusters to your dataframe as a new column to include in the next step and write the updated dataframe out as csv. Save the dataframe in the data folder and name it `step3_output.csv`.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L_tqS8h4-Xc"
   },
   "outputs": [],
   "source": [
    "# Make a new column in your dfno dataframe called 'clusters', and assign it the variable: y_kmeans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCTz-F2h4-Xf"
   },
   "outputs": [],
   "source": [
    "# Write your dataframe to csv "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GuidedCapstoneStep3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
